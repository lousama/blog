<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Spark学习笔记之入门篇一 | Lousama</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. 概括每个Spark程序都包括一个主驱动程序和在集群上执行的并行操作。Spark一个重要的抽象模型是RDD(resilient distributed dataset)，中文翻译呢，就是弹性分布式数据集，弹性呢，指的其实是可以在集群中跨节点和分区。RDDs的创建呢，可以通过一个本地文件，或者HDFS，或者一个现有的Scala集合，甚至其他的RDD通过transformation(RDD的一个基">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark学习笔记之入门篇一">
<meta property="og:url" content="http://lousama.com/2016/01/11/Spark入门篇/index.html">
<meta property="og:site_name" content="Lousama">
<meta property="og:description" content="1. 概括每个Spark程序都包括一个主驱动程序和在集群上执行的并行操作。Spark一个重要的抽象模型是RDD(resilient distributed dataset)，中文翻译呢，就是弹性分布式数据集，弹性呢，指的其实是可以在集群中跨节点和分区。RDDs的创建呢，可以通过一个本地文件，或者HDFS，或者一个现有的Scala集合，甚至其他的RDD通过transformation(RDD的一个基">
<meta property="og:updated_time" content="2016-01-11T17:33:27.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark学习笔记之入门篇一">
<meta name="twitter:description" content="1. 概括每个Spark程序都包括一个主驱动程序和在集群上执行的并行操作。Spark一个重要的抽象模型是RDD(resilient distributed dataset)，中文翻译呢，就是弹性分布式数据集，弹性呢，指的其实是可以在集群中跨节点和分区。RDDs的创建呢，可以通过一个本地文件，或者HDFS，或者一个现有的Scala集合，甚至其他的RDD通过transformation(RDD的一个基">
  
  
    <link rel="icon" type="image/x-icon" href="/img/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
 
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/avatar.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Lousama</a></h1>
		</hgroup>

		
		<p class="header-subtitle">道狭草木长，夕露沾我衣</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">Home</a></li>
				        
							<li><a href="/archives">Archives</a></li>
				        
							<li><a href="/categories/Java">Java</a></li>
				        
							<li><a href="/categories/Linux">Linux</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/lousama" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/lousama" title="weibo">weibo</a>
					        
								<a class="facebook" target="_blank" href="https://www.facebook.com/sama.lou.52" title="facebook">facebook</a>
					        
								<a class="twitter" target="_blank" href="https://twitter.com/lougooo" title="twitter">twitter</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Homebrew/" style="font-size: 10px;">Homebrew</a> <a href="/tags/Java/" style="font-size: 20px;">Java</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MapReduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/Netty/" style="font-size: 10px;">Netty</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Shell/" style="font-size: 10px;">Shell</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/grep/" style="font-size: 10px;">grep</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/pgg/" style="font-size: 15px;">pgg</a> <a href="/tags/servlet/" style="font-size: 10px;">servlet</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/事故/" style="font-size: 10px;">事故</a> <a href="/tags/生产/" style="font-size: 10px;">生产</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://www.jianshu.com/users/69e7d01b513e">13c mid-out Android</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://blog.2baxb.me">axb</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://blog.aquariuslt.com/">instigates male little A</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Lousama</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/img/avatar.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Lousama</h1>
			</hgroup>
			
			<p class="header-subtitle">道狭草木长，夕露沾我衣</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">Home</a></li>
		        
					<li><a href="/archives">Archives</a></li>
		        
					<li><a href="/categories/Java">Java</a></li>
		        
					<li><a href="/categories/Linux">Linux</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/lousama" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/lousama" title="weibo">weibo</a>
			        
						<a class="facebook" target="_blank" href="https://www.facebook.com/sama.lou.52" title="facebook">facebook</a>
			        
						<a class="twitter" target="_blank" href="https://twitter.com/lougooo" title="twitter">twitter</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-Spark入门篇" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/01/11/Spark入门篇/" class="article-date">
  	<time datetime="2016-01-11T03:34:12.000Z" itemprop="datePublished">2016-01-11</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark学习笔记之入门篇一
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Scala/">Scala</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Spark/">Spark</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-__u6982_u62EC"><a href="#1-__u6982_u62EC" class="headerlink" title="1. 概括"></a>1. 概括</h1><p>每个Spark程序都包括一个主驱动程序和在集群上执行的并行操作。<br>Spark一个重要的抽象模型是<strong>RDD(resilient distributed dataset)</strong>，中文翻译呢，就是弹性分布式数据集，弹性呢，指的其实是可以在集群中跨节点和分区。RDDs的创建呢，可以通过一个本地文件，或者HDFS，或者一个现有的Scala集合，甚至其他的RDD通过<strong>transformation(RDD的一个基本操作之一，后面会讲到)</strong>得来。用户也可以把一个RDD持久化到内存中，可以在并行操作中更高效的复用。还有非常重要的一点，RDDs出现节点故障时可以自动恢复。<br><a id="more"></a><br>Spark另一个抽象概念是可以在并行操作中共享变量，默认Spark在不同节点的任务集并行执行一个方法的时候，它会复制每一个变量到每一个任务中，有时变量需要跨任务共享。</p>
<p>Spark支持两种共享变量模式：</p>
<blockquote>
<ul>
<li><strong>广播变量(broadcast variables)：</strong><ul>
<li>可以缓存值在所有节点的内存中。</li>
</ul>
</li>
<li><strong>累加器(accumulators)：</strong><ul>
<li>只能通过“added”得到的变量，类似计数器或求和。 </li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="2-__u5B89_u88C5"><a href="#2-__u5B89_u88C5" class="headerlink" title="2. 安装"></a>2. 安装</h1><p>这里的安装只说一下Linux和Mac OS X系统下的安装。</p>
<h2 id="2-1_OS_X"><a href="#2-1_OS_X" class="headerlink" title="2.1 OS X"></a>2.1 OS X</h2><p>OS X就简单了，直接homebrew无脑安装，什么？你还不知道homebrew？ <a href="/2015/07/11/homebrew/">点我安装</a></p>
<h3 id="2-1-1__u5B89_u88C5scala"><a href="#2-1-1__u5B89_u88C5scala" class="headerlink" title="2.1.1 安装scala"></a>2.1.1 安装scala</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install scala</span><br></pre></td></tr></table></figure>
<h3 id="2-1-2__u5B89_u88C5git"><a href="#2-1-2__u5B89_u88C5git" class="headerlink" title="2.1.2 安装git"></a>2.1.2 安装git</h3><p>因为pgg自带git，所以这一步就不需要啦</p>
<h3 id="2-1-3__u5B89_u88C5spark"><a href="#2-1-3__u5B89_u88C5spark" class="headerlink" title="2.1.3 安装spark"></a>2.1.3 安装spark</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install spark</span><br></pre></td></tr></table></figure>
<p>呵呵，so easy?</p>
<h2 id="2-2_Linux"><a href="#2-2_Linux" class="headerlink" title="2.2 Linux"></a>2.2 Linux</h2><p>Linux安装的话，也一次是上述步骤</p>
<h3 id="2-2-1__u5B89_u88C5scala"><a href="#2-2-1__u5B89_u88C5scala" class="headerlink" title="2.2.1 安装scala"></a>2.2.1 安装scala</h3><p>到<a href="http://www.scala-lang.org/old/node/165" target="_blank" rel="external">官网</a>下载最新的版本，解压后放在本地<code>/opt</code>下。<br>在<code>/etc/profile</code>里添加：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SCALA_HOME=/opt/scala-<span class="number">2.9</span>.<span class="number">1</span>.final</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SCALA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></p>
<h3 id="2-2-2__u5B89_u88C5git"><a href="#2-2-2__u5B89_u88C5git" class="headerlink" title="2.2.2 安装git"></a>2.2.2 安装git</h3><p>到<a href="http://git-scm.com/download/linux" target="_blank" rel="external">官网</a> 查看不同版本Linux下git的安装，使用默认配置。</p>
<h3 id="2-1-3__u5B89_u88C5spark-1"><a href="#2-1-3__u5B89_u88C5spark-1" class="headerlink" title="2.1.3 安装spark"></a>2.1.3 安装spark</h3><p>下载最新源码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git://github.com/mesos/spark.git</span><br></pre></td></tr></table></figure></p>
<p>得到目录spark后，进入spark目录，进入conf子目录，将 spark-env.sh-template 重命名为spark-env.sh，并添加以下代码行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SCALA_HOME=/opt/scala-<span class="number">2.9</span>.<span class="number">1</span>.final</span><br></pre></td></tr></table></figure></p>
<p>回到spark目录，开始编译，运行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbt/sbt update compile</span><br></pre></td></tr></table></figure></p>
<p>这条命令会联网下载很多jar，然后会对spark进行编译，编译完成会提示success</p>
<p>Spark自带了一些例子程序，在<code>examples/src/main</code>目录，OS X是<code>libexec/examples/src/main</code>，在要运行的话可以在Spark根目录执行<code>bin/run-example &lt;class&gt; [params]</code>口令，例如计算pi值<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/run-example SparkPi <span class="number">10</span></span><br></pre></td></tr></table></figure></p>
<p>执行下列命令可以在命令行启动交互：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-shell</span><br></pre></td></tr></table></figure></p>
<p>然后启动日志里会有这么一句：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SparkUI: Started SparkUI at http://<span class="number">172.18</span>.<span class="number">1.101</span>:<span class="number">4040</span></span><br></pre></td></tr></table></figure></p>
<p>在浏览器输入上述地址则可以在浏览器中查看执行的job。</p>
<p>spark-shell启动后可以执行scala命令。</p>
<h1 id="3-__u5F15_u5165"><a href="#3-__u5F15_u5165" class="headerlink" title="3. 引入"></a>3. 引入</h1><p>在Java中引入spark的话，可以在pom.xml中加入：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.6.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>
<p>如果你想在HDFS集群中访问的话，可以添加一个对应版本的hadoop-client的依赖：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;&lt;your-hdfs-version&gt;&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>
<p>Java类中需要引入的包基本如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br></pre></td></tr></table></figure></p>
<h1 id="4-RDD"><a href="#4-RDD" class="headerlink" title="4.RDD"></a>4.RDD</h1><p>RDDs支持两种类型的操作：</p>
<blockquote>
<ul>
<li><strong> transformations: </strong><ul>
<li>根据一个现有的RDD生成一个新的RDD   </li>
</ul>
</li>
<li><strong> actions: </strong><ul>
<li>计算返回结果</li>
</ul>
</li>
</ul>
</blockquote>
<p>例如，<code>map</code>就是通过对一个数据集中每个元素执行指定的方法返回一个新的RDD作为结果。那<code>reduce</code>呢，就是对数据集中的元素通过指定的方法进行合并然后返回结果给驱动程序。</p>
<p>所有的 <code>transformations</code> 操作都是延迟计算的，就是说不会马上计算出结果，<code>transformations</code> 只有在一个 <code>action</code> 操作需要返回结果的时候才会被计算。<br>这个设计可以让Spark有非常高的性能，例如我们能实现通过<code>map</code>生成一个RDD，用作于在<code>reduce</code>中计算，然后只把计算结果返回给驱动程序，而不是整个映射的数据集。</p>
<p>默认的，每个转换过的RDD都有可能在执行action的时候被重新计算，所以你也可以调用<code>persist()</code>或者 <code>cache()</code>把RDD持久化到内存中。这样的话下次访问的话将会更快，Spark同样也支持持久化到磁盘，以及跨越节点复制。</p>
<h1 id="5-__u793A_u4F8B"><a href="#5-__u793A_u4F8B" class="headerlink" title="5. 示例"></a>5. 示例</h1><h2 id="5-1_sum"><a href="#5-1_sum" class="headerlink" title="5.1 sum"></a>5.1 sum</h2><p>下面将通过示例代码逐步讲解Spark如何使用以及如果操作RDD，语言为Java：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"test"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line">List&lt;Integer&gt; list = Arrays.asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; distData = sc.parallelize(list);</span><br><span class="line"><span class="keyword">int</span> sum = distData.reduce((a, b) -&gt; a + b);</span><br><span class="line">System.out.println(sum);</span><br></pre></td></tr></table></figure></p>
<p>上面这段代码实现了求list里所有元素的和。<br>我们来逐条分析</p>
<ul>
<li><strong><code>SparkConf conf = new SparkConf().setAppName(&quot;test&quot;).setMaster(&quot;local&quot;);</code></strong></li>
<li><strong><code>JavaSparkContext sc = new JavaSparkContext(conf);</code></strong></li>
</ul>
<p>写一个Spark程序首先要做的是创建一个<code>JavaSparkContext</code>对象，这个对象需要加载<code>SparkConf</code>，<code>SparkConf</code>里包含了应用程序的相关信息。<br>参数<code>test</code>是展示在集群UI上的应用名称，<br>参数<code>local</code>表示程序运行在本地模式，所以，这个值还阔以是Spark,Mesos或YARN集群的URL，关于集群的配置后续集群篇中会再提到。</p>
<ul>
<li><strong><code>JavaRDD&lt;Integer&gt; distData = sc.parallelize(list);</code></strong><br>第三行代码new一个list就不用多说了，看第四行，<code>JavaRDD</code> 就是一个Java的RDD对象。<br>Java常用的RDD对象有以下三种：<blockquote>
<ul>
<li>JavaRDD: 普通RDD对象，也是最常用的RDD对象，存储字符串，整形等类型数据。</li>
<li>JavaPairRDD: K-V的RDD对象，存储Key-Value对象。</li>
<li>JavaDoubleRDD: double类型的RDD对象，存储浮点型和长整形对象。</li>
</ul>
</blockquote>
</li>
</ul>
<p>上述第四行代码中一个RDD对象distData通过调用<code>JavaSparkContext’s parallelize()</code>方法由一个现有的集合list创建。<br>JavaSparkContext创建RDD常用的方法有以下两种<del>其实是我暂时就会这两种</del>：</p>
<blockquote>
<ul>
<li><strong>public <t> JavaRDD<t> parallelize(List<t> list)</t></t></t></strong><ul>
<li>用于通过集合创建RDD。</li>
</ul>
</li>
<li><strong>public JavaRDD<string> textFile(String path)</string></strong><ul>
<li>从文件中创建RDD。path参数为文件的绝对路径。</li>
</ul>
</li>
</ul>
</blockquote>
<p>RDD还有一个很重要的参数就是partitions(分片)的数量，Spark在集群上的每个分片运行一个任务，你可以在集群上给每个CPU设置2-4个分片。通常，Spark会基于集群状况自动设置分片数量，当然你也可以通过上述两个方法的第二个参数来传入要设定的分片数量。如：<code>sc.parallelize(list,10)</code>。</p>
<ul>
<li><strong><code>int sum = distData.reduce((a, b) -&gt; a + b);</code></strong><br>reduce()是一个action操作，Spark 把计算分成多个任务(task)，并且让它们运行在多个机器上。每台机器都运行自己的reduce 部分。然后仅仅将结果返回。<br>上述的方法内部是一个lambda表达式，表示把两个元素相加。<br>只有JDK1.8及之上的版本才支持lambda语法，如果较低版本的话可以实现接口<code>org.apache.spark.api.java.function</code>。</li>
</ul>
<p>上述代码运行结果是 <code>15</code>。</p>
<h2 id="5-2_wordCount"><a href="#5-2_wordCount" class="headerlink" title="5.2 wordCount"></a>5.2 wordCount</h2><p>下面再展示一个wordCount的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"wordCount"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line">JavaRDD&lt;String&gt; distFile = sc.textFile(<span class="string">"/Users/apple/Documents/spark"</span>);</span><br><span class="line">distFile.cache();</span><br><span class="line">JavaRDD&lt;String&gt; words = distFile.flatMap(s -&gt; Arrays.asList(s.split(<span class="string">" "</span>)));</span><br><span class="line">JavaPairRDD&lt;String,Integer&gt; results = words.mapToPair(word -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(word, <span class="number">1</span>)).reduceByKey((a, b) -&gt; a + b);</span><br><span class="line">results.collection().forEach(tuple -&gt; System.out.println(<span class="string">"flatMap"</span> + tuple._1 + <span class="string">":"</span> + tuple._2));</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/01/08/Spark学习笔记/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Spark学习笔记之简介篇</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">Share to: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_weixin"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathisiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="Spark入门篇" data-title="Spark学习笔记之入门篇一" data-url="http://lousama.com/2016/01/11/Spark入门篇/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"lousama"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
      </script>
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2015 Lousama
          <span id="busuanzi_container_site_pv">
              Total:<span id="busuanzi_value_site_pv"></span>
          </span>
    	</div>
      
      	<div class="footer-right">
          Life for you,for coding
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



  </div>
</body>
</html>